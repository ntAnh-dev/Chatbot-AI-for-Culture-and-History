import time
import random
from googlesearch import search
from newspaper import Article
import logging
from pathlib import Path
import json

logging.basicConfig(filename="crawl_errors.log", level=logging.WARNING)

def extract_article_safe(url):
    try:
        article = Article(url, language='vi')
        article.download()
        article.parse()
        return article.text
    except Exception as e:
        logging.warning(f"Fail at {url}: {e}")
        return None

# folder_path = Path("../ÄiÌ€nh, Ä‘eÌ‚Ì€n, chuÌ€a VieÌ£Ì‚t Nam")
# pdf_files = [f.stem for f in folder_path.glob("*.pdf")]

def is_figure(text):
    forbidden_words = ["Ä‘Ã¬nh", "Ä‘á»n", "chÃ¹a", "miáº¿u", "Ä‘á»“n", "lá»… há»™i"]
    return not any(word in text.lower() for word in forbidden_words)

with open('../research/entities.json', 'r', encoding='utf-8') as f:
    json_data = json.load(f)
# json_data = json.loads('../research/entities.json')

converted_names = []

# for name in pdf_files:
#     if " - " in name:
#         dia_phuong, ten_den = name.split(" - ", 1)
#         # converted = f"Lá»… há»™i {ten_den} - {dia_phuong}"
#         converted = f"{ten_den} - {dia_phuong}"
#         converted_names.append(converted)
#     # else:
#     #     converted_names.append(name)

for item in json_data:
    for subitem in item:
        # if is_figure(subitem[0]) and not subitem[0] in converted_names:
            # converted_names.append(subitem[0])

        for subsubitem in subitem:
            if is_figure(subsubitem) and not subsubitem in converted_names:
                converted_names.append(subsubitem)
            break

crawled_json = {}

print(len(converted_names))
i = 0

for festival in converted_names:
    i+=1
    print(i)
    print(f"ğŸ” Äang tÃ¬m kiáº¿m: {festival}")
    try:
        urls = list(search(festival, num_results=5))
    except Exception as e:
        print(f"âŒ Lá»—i khi tÃ¬m kiáº¿m Google: {e}")
        continue

    temp = {}
    for url in urls:
        print(f"â¬ Láº¥y bÃ i tá»«: {url}")
        text = extract_article_safe(url)
        if text:
            temp[url] = text
        else:
            print(f"Bá» qua {url} vÃ¬ lá»—i.\n")
        
        # ğŸ’¤ Nghá»‰ ngáº«u nhiÃªn sau má»—i request (giáº£m nguy cÆ¡ bá»‹ cháº·n)
        time.sleep(5)

    crawled_json[festival] = temp
    print(f"âœ… ÄÃ£ lÆ°u dá»¯ liá»‡u {festival}.\n")

    # ğŸ’¤ Delay sau má»—i láº§n tÃ¬m kiáº¿m Google (trÃ¡nh Google block IP)
    time.sleep(20)

# Ghi ra file JSON
with open("figure_crawl.json", "w", encoding="utf-8") as f:
    json.dump(crawled_json, f, ensure_ascii=False, indent=2)

print("âœ… ÄÃ£ lÆ°u figure_crawl.json")
